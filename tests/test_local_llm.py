"""
Tests for local_llm module.

Tests the MLX-based local LLM functionality:
- Availability checking
- Model loading (mocked)
- Text generation (mocked)
- Fallback behavior when MLX unavailable
"""

import pytest
from unittest.mock import Mock, patch, MagicMock


class TestIsAvailable:
    """Tests for is_available() function."""

    def test_returns_true_when_mlx_available(self):
        """is_available() returns True when MLX is installed."""
        with patch.dict('sys.modules', {'mlx': Mock(), 'mlx_lm': Mock()}):
            # Need to reload the module to pick up the mocked imports
            from handfree import local_llm
            # Reset the module state
            local_llm._model = None
            local_llm._tokenizer = None
            local_llm._current_model_name = None

            # Check availability with mocked imports
            with patch('handfree.local_llm.is_available', return_value=True):
                assert local_llm.is_available() is True

    def test_returns_false_when_mlx_not_available(self):
        """is_available() returns False when MLX is not installed."""
        from handfree import local_llm

        # Test the actual is_available function behavior
        # It should return False if MLX is not installed
        # We can mock the import to fail
        original_is_available = local_llm.is_available

        def mock_is_available():
            try:
                import mlx
                import mlx_lm
                return True
            except ImportError:
                return False

        # The actual implementation checks for ImportError
        # If MLX is not installed, it will return False
        result = local_llm.is_available()
        # Result depends on whether MLX is actually installed
        assert isinstance(result, bool)


class TestGetModel:
    """Tests for get_model() function."""

    @patch('handfree.local_llm.is_available', return_value=False)
    def test_raises_when_mlx_not_available(self, mock_available):
        """get_model() raises ImportError when MLX not installed."""
        from handfree import local_llm

        # Reset module state
        local_llm._model = None
        local_llm._tokenizer = None
        local_llm._current_model_name = None

        with pytest.raises(ImportError):
            # This will raise because mlx_lm.load cannot be imported
            local_llm.get_model()

    def test_returns_cached_model_on_second_call(self):
        """get_model() returns cached model on subsequent calls."""
        from handfree import local_llm

        # Set up cached model
        mock_model = Mock()
        mock_tokenizer = Mock()
        local_llm._model = mock_model
        local_llm._tokenizer = mock_tokenizer
        local_llm._current_model_name = "test-model"

        try:
            # Should return cached model without loading
            model, tokenizer = local_llm.get_model("test-model")
            assert model == mock_model
            assert tokenizer == mock_tokenizer
        finally:
            # Cleanup
            local_llm._model = None
            local_llm._tokenizer = None
            local_llm._current_model_name = None


class TestGenerate:
    """Tests for generate() function."""

    def test_generate_raises_import_error_when_mlx_not_installed(self):
        """generate() raises ImportError when mlx_lm not installed."""
        from handfree import local_llm

        # Reset module state
        local_llm._model = None
        local_llm._tokenizer = None
        local_llm._current_model_name = None

        # Since mlx_lm is not installed, this should raise
        with pytest.raises((ImportError, ModuleNotFoundError)):
            local_llm.generate("Test prompt")

    def test_generate_error_handling(self):
        """generate() handles errors gracefully."""
        from handfree import local_llm

        # Reset module state
        local_llm._model = None
        local_llm._tokenizer = None
        local_llm._current_model_name = None

        # Should raise an exception when mlx_lm is not available
        with pytest.raises(Exception):
            local_llm.generate("Test prompt")


class TestUnloadModel:
    """Tests for unload_model() function."""

    def test_clears_model_state(self):
        """unload_model() clears all model state."""
        from handfree import local_llm

        # Set up some state
        local_llm._model = Mock()
        local_llm._tokenizer = Mock()
        local_llm._current_model_name = "test-model"

        # Unload
        local_llm.unload_model()

        # Verify cleared
        assert local_llm._model is None
        assert local_llm._tokenizer is None
        assert local_llm._current_model_name is None

    def test_safe_to_call_multiple_times(self):
        """unload_model() is safe to call multiple times."""
        from handfree import local_llm

        # Should not raise
        local_llm.unload_model()
        local_llm.unload_model()
        local_llm.unload_model()


class TestGetCurrentModelName:
    """Tests for get_current_model_name() function."""

    def test_returns_none_when_no_model_loaded(self):
        """get_current_model_name() returns None when no model loaded."""
        from handfree import local_llm

        local_llm._model = None
        local_llm._current_model_name = None

        assert local_llm.get_current_model_name() is None

    def test_returns_model_name_when_loaded(self):
        """get_current_model_name() returns model name when loaded."""
        from handfree import local_llm

        local_llm._current_model_name = "test-model"

        try:
            assert local_llm.get_current_model_name() == "test-model"
        finally:
            local_llm._current_model_name = None


class TestModelSwitching:
    """Tests for model switching behavior."""

    def test_model_state_cleared_on_switch_request(self):
        """Model state is cleared when different model is requested."""
        from handfree import local_llm

        # Set up initial model state
        local_llm._model = Mock()
        local_llm._tokenizer = Mock()
        local_llm._current_model_name = "model-a"

        try:
            # Request a different model - this will clear state before loading
            # Since mlx_lm is not installed, it will raise after clearing
            local_llm.get_model("model-b")
        except (ImportError, ModuleNotFoundError):
            # Expected since mlx_lm is not installed
            pass

        # After failed load attempt, state should be None
        # (the get_model function clears state when switching)
        # Actually, looking at the code, it clears state via unload_model
        # before attempting to load the new model

        # Cleanup
        local_llm._model = None
        local_llm._tokenizer = None
        local_llm._current_model_name = None

    def test_same_model_reuses_cache(self):
        """Same model name reuses cached model."""
        from handfree import local_llm

        mock_model = Mock()
        mock_tokenizer = Mock()

        # Set up cached model state
        local_llm._model = mock_model
        local_llm._tokenizer = mock_tokenizer
        local_llm._current_model_name = "cached-model"

        try:
            # Request same model - should return cached
            model, tokenizer = local_llm.get_model("cached-model")
            assert model is mock_model
            assert tokenizer is mock_tokenizer
        finally:
            # Cleanup
            local_llm._model = None
            local_llm._tokenizer = None
            local_llm._current_model_name = None


class TestTextCleanerWithLocalLLM:
    """Tests for TextCleaner using local LLM."""

    def test_aggressive_mode_with_model_name(self):
        """TextCleaner accepts model_name for aggressive mode."""
        from handfree.text_cleanup import TextCleaner, CleanupMode

        cleaner = TextCleaner(
            mode=CleanupMode.AGGRESSIVE,
            model_name="mlx-community/Phi-3-mini-4k-instruct-4bit"
        )

        assert cleaner.mode == CleanupMode.AGGRESSIVE
        assert cleaner.model_name == "mlx-community/Phi-3-mini-4k-instruct-4bit"

    def test_aggressive_mode_default_model(self):
        """TextCleaner uses default model when none specified."""
        from handfree.text_cleanup import TextCleaner, CleanupMode

        cleaner = TextCleaner(mode=CleanupMode.AGGRESSIVE)

        assert cleaner.model_name == cleaner.DEFAULT_MODEL

    @patch('handfree.local_llm.is_available', return_value=False)
    def test_aggressive_falls_back_when_mlx_unavailable(self, mock_available):
        """Aggressive mode falls back to standard when MLX unavailable."""
        from handfree.text_cleanup import TextCleaner, CleanupMode

        cleaner = TextCleaner(mode=CleanupMode.AGGRESSIVE)

        text = "Um, hello there"
        result = cleaner.clean(text)

        # Should still clean using standard mode fallback
        assert "Um" not in result
        assert "hello" in result.lower()

    @patch('handfree.local_llm.is_available', return_value=True)
    @patch('handfree.local_llm.generate')
    def test_aggressive_uses_local_llm_when_available(self, mock_generate, mock_available):
        """Aggressive mode uses local LLM when available."""
        from handfree.text_cleanup import TextCleaner, CleanupMode

        mock_generate.return_value = "Hello there"

        cleaner = TextCleaner(mode=CleanupMode.AGGRESSIVE)

        text = "Um, hello there"
        result = cleaner.clean(text)

        mock_generate.assert_called_once()
        assert result == "Hello there"

    @patch('handfree.local_llm.is_available', return_value=True)
    @patch('handfree.local_llm.generate')
    def test_aggressive_falls_back_on_generation_error(self, mock_generate, mock_available):
        """Aggressive mode falls back on LLM generation error."""
        from handfree.text_cleanup import TextCleaner, CleanupMode

        mock_generate.side_effect = Exception("Generation failed")

        cleaner = TextCleaner(mode=CleanupMode.AGGRESSIVE)

        text = "Um, hello there"
        result = cleaner.clean(text)

        # Should fall back to standard mode
        assert "Um" not in result
        assert "hello" in result.lower()

    @patch('handfree.local_llm.is_available', return_value=True)
    @patch('handfree.local_llm.generate')
    def test_aggressive_falls_back_when_too_much_removed(self, mock_generate, mock_available):
        """Aggressive mode falls back when LLM removes too much text."""
        from handfree.text_cleanup import TextCleaner, CleanupMode

        # Return very short text (< 30% of original)
        mock_generate.return_value = "Hi"

        cleaner = TextCleaner(mode=CleanupMode.AGGRESSIVE)

        text = "Um, this is a longer piece of text that should not be reduced to just Hi"
        result = cleaner.clean(text)

        # Should fall back to standard mode since LLM output was too short
        assert len(result) > len("Hi")


class TestConfigLocalModel:
    """Tests for local_model configuration."""

    def test_config_has_local_model_field(self):
        """Config dataclass has local_model field."""
        from handfree.config import Config

        config = Config(transcriber="local")
        assert hasattr(config, 'local_model')
        assert config.local_model == "mlx-community/Phi-3-mini-4k-instruct-4bit"

    def test_config_reads_local_model_from_env(self):
        """Config reads HANDFREE_LOCAL_MODEL from environment."""
        import os
        from unittest.mock import patch
        from handfree.config import Config

        with patch.dict(os.environ, {
            "HANDFREE_LOCAL_MODEL": "custom-model",
            "HANDFREE_TRANSCRIBER": "local"
        }, clear=False):
            config = Config.from_env()
            assert config.local_model == "custom-model"

    def test_config_uses_default_local_model(self):
        """Config uses default local model when not specified."""
        import os
        from unittest.mock import patch
        from handfree.config import Config

        env_copy = os.environ.copy()
        env_copy.pop("HANDFREE_LOCAL_MODEL", None)
        env_copy["HANDFREE_TRANSCRIBER"] = "local"

        with patch.dict(os.environ, env_copy, clear=True):
            config = Config.from_env()
            assert config.local_model == "mlx-community/Phi-3-mini-4k-instruct-4bit"


class TestFactoryWithLocalModel:
    """Tests for get_text_cleaner factory with local model."""

    def test_factory_passes_model_name_to_cleaner(self):
        """Factory passes local_model from config to cleaner."""
        from main import get_text_cleaner
        from unittest.mock import Mock

        config = Mock()
        config.text_cleanup = "aggressive"
        config.local_model = "custom-model"
        config.preserve_intentional = True

        cleaner = get_text_cleaner(config)

        assert cleaner.model_name == "custom-model"

    def test_factory_creates_aggressive_mode_cleaner(self):
        """Factory creates aggressive mode cleaner with model name."""
        from main import get_text_cleaner
        from handfree.text_cleanup import CleanupMode
        from unittest.mock import Mock

        config = Mock()
        config.text_cleanup = "aggressive"
        config.local_model = "mlx-community/Phi-3-mini-4k-instruct-4bit"
        config.preserve_intentional = True

        cleaner = get_text_cleaner(config)

        assert cleaner.mode == CleanupMode.AGGRESSIVE
        assert cleaner.model_name == "mlx-community/Phi-3-mini-4k-instruct-4bit"
